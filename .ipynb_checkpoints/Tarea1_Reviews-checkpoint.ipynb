{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Tarea 1 - Amazon Food Reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "En primer lugar se importarán todas las librerías a utilizar:\n",
    "BeautifulSoup: Para eliminar el código HTML de la reseña.\n",
    "nltk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reviews = open(\"amazon-fine-foods/Reviews.csv\", \"r\")\n",
    "\n",
    "corpus = []\n",
    "score = []\n",
    "\n",
    "reviews.readline()\n",
    "\n",
    "for line in reviews:\n",
    "    review = line.strip().split(\",\")\n",
    "    text = BeautifulSoup(review[-1], 'html.parser')\n",
    "    corpus.append([text.get_text()])\n",
    "    score.append(review[6])\n",
    "\n",
    "reviews.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.'], [u'\"Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"\"Jumbo\"\".\"']]\n"
     ]
    }
   ],
   "source": [
    "print corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokens = []\n",
    "for doc in corpus:\n",
    "    tokens += nltk.word_tokenize(doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 17255960\n",
      " 20 first tokens: \n",
      "[u'I', u'have', u'bought', u'several', u'of', u'the', u'Vitality', u'canned', u'dog', u'food', u'products', u'and', u'have', u'found', u'them', u'all', u'to', u'be', u'of', u'good']\n"
     ]
    }
   ],
   "source": [
    "print \"Total Tokens: %d\" % len(tokens)\n",
    "print \" 20 first tokens: \"\n",
    "print tokens[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'bought', u'several', u'vitality', u'canned', u'dog', u'food', u'products', u'found', u'good', u'quality', u'.', u'product', u'looks', u'like', u'stew', u'processed', u'meat', u'smells', u'better', u'.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stoplist = stopwords.words('english')\n",
    "# filtered tokens\n",
    "tokens = [token.lower() for token in tokens if token.lower() not in stoplist]\n",
    "\n",
    "print tokens[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7342622\n"
     ]
    }
   ],
   "source": [
    "tokens = [token for token in tokens if len(token) >= 3]\n",
    "print len(tokens)\n",
    "frec_dist = nltk.FreqDist(tokens) #terminos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "terminos = [token for token in tokens if frec_dist[token] >= 4]  #Cambiar frecuencia umbral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'-protien', u'hemp-protien'), (u'-smirch', u'centennial'), (u'.false', u'adversing'), (u'.hard', u'sugarrio'), (u'.quel', u'bonheur'), (u'.steak', u'frites-'), (u'//www.drbronner.com/pdf/hempnutrition.pdfhttp', u'//sudburymarket.com/nutritional_benefits_hemp.html'), (u'//www.ratical.org/renewables/hempseed1.htmlhttp', u'//www.drbronner.com/pdf/hempnutrition.pdfhttp'), (u'22.37', u'96-pack'), (u'3.40/oz', u'2.62/oz'), (u'36.99', u'/80'), (u'45carbs', u'gmsodium'), (u'95lb', u'pitbull/'), (u'=1298166499', u'=1-1-catcorr'), (u'a.l', u'walton'), (u'abctoy4me', u'toysdiva'), (u'amazon.sylvia', u'lorenzano'), (u'antioxdent', u'ithelps'), (u'baltasar', u'gracian'), (u'bay/fog', u'chaserwas'), (u'bicardi', u'oakheart'), (u'broke.edit', u'5/6/10i'), (u'brownieok', u'flavorspretty'), (u'buy.sincerelydanny', u'knowles'), (u'camellia', u'sinensis'), (u'cappuccino.just', u'greaaat'), (u'cheeaper', u'petsmarthowever'), (u'confindent', u'*star*'), (u'craggles', u'wondermentsperfection'), (u'crags', u'craggles')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(terminos)\n",
    "top_collocations = finder.nbest(bigram_measures.pmi, 30) #top 30 bigramas\n",
    "print top_collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'bought', u'VBD'), (u'several', u'JJ'), (u'vitality', u'NN'), (u'canned', u'VBD'), (u'dog', u'NN'), (u'food', u'NN'), (u'products', u'NNS'), (u'found', u'VBD'), (u'good', u'JJ'), (u'quality', u'NN')]\n",
      "[(u'bought', 'VBD'), (u'several', 'JJ'), (u'vitality', 'NN'), (u'canned', 'VBD'), (u'dog', 'JJ'), (u'food', 'NN'), (u'products', 'NNS'), (u'found', 'VBD'), (u'good', 'JJ'), (u'quality', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import StanfordPOSTagger\n",
    "\n",
    "# Add the jar and model via their path (instead of setting environment variables):\n",
    "# Route Fena\n",
    "#jar = '~/Documentos/2017-1/WebMining/Tarea1/stanford-postagger-2016-10-31/stanford-postagger.jar'\n",
    "#model = '~/Documentos/2017-1/WebMining/Tarea1/stanford-postagger-2016-10-31/models/english-bidirectional-distsim.tagger'\n",
    "# Route nacho\n",
    "jar = 'pos-tagger/stanford-postagger.jar'\n",
    "model = 'pos-tagger/english-bidirectional-distsim.tagger'\n",
    "\n",
    "\n",
    "st = StanfordPOSTagger(model,jar)\n",
    "print st.tag(terminos[:100])[:10]\n",
    "#print st[:10]\n",
    "tagged = nltk.pos_tag(terminos[:100])\n",
    "print tagged[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "st = StanfordNERTagger('english.all.3class.distsim.crf.ser.gz') \n",
    "ner = st.tag(terminos)\n",
    "print ner[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
